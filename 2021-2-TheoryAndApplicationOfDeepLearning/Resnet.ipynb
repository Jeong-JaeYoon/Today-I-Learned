{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv\n",
    "import random\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jj950\\Desktop\\workspace\\Today-I-Learned\\2021-2-TheoryAndApplicationOfDeepLearning\n",
      "['archive', 'archive.zip', 'Resnet.ipynb', 'test2.py']\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_three_samples(letter):\n",
    "    print(\"Samples images for letter\", letter)\n",
    "    path = 'archive/asl_alphabet_train/asl_alphabet_train/'\n",
    "    img_path = path + letter + '/**'\n",
    "    path_contents = glob(img_path)\n",
    "    \n",
    "    plt.figure(figsize=(16,16))\n",
    "    imgs = random.sample(path_contents, 3)\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(cv2.imread(imgs[0]))\n",
    "    plt.subplot(132)\n",
    "    plt.imshow(cv2.imread(imgs[1]))\n",
    "    plt.subplot(133)\n",
    "    plt.imshow(cv2.imread(imgs[2]))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples images for letter A\n"
     ]
    }
   ],
   "source": [
    "plot_three_samples('A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'archive/asl_alphabet_train/asl_alphabet_train/'\n",
    "\n",
    "transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(data_path, transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 87000\n",
      "    Root location: archive/asl_alphabet_train/asl_alphabet_train/\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=256, interpolation=bilinear, max_size=None, antialias=None)\n",
      "               RandomCrop(size=(224, 224), padding=None)\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8b4d6a0c14dec02419a5baa7b05cba6417b25af0a78599953b93cb717ec482ae"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
